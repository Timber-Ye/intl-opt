{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de51fe82-7e17-4161-94cb-9880954eb634",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Forward Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "DATA_DIR = './data/sales_predict_train.csv'\n",
    "\n",
    "lr = 1e-2\n",
    "n_epochs = 1000  # number of epochs\n",
    "\n",
    "INPUT_DIM = 3  # dimension of feature\n",
    "OUTPUT_DIM = 1  # dimension of target\n",
    "HIDDEN_NUM = 5  # size of hidden layer\n",
    "\n",
    "maxValue = 3000  # 假设最大利润不超过3000\n",
    "minValue = 0  # 最低利润为0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "raw_data = [2056, 2395, 2600, 2298, 1634, 1600, 1873, 1478, 1900]\n",
    "\n",
    "# 线性归一化处理\n",
    "raw_data = (np.array(raw_data) - minValue) / (maxValue - minValue)\n",
    "features = np.array([raw_data[i:i+3] for i in range(raw_data.shape[0] - 3)])\n",
    "predict = np.array([raw_data[i] for i in range(3, raw_data.shape[0])])\n",
    "data = np.hstack((features.reshape(-1, 3), predict.reshape(-1, 1)))\n",
    "\n",
    "np.savetxt(DATA_DIR, data, delimiter=',', newline='\\n', header=\"x0,x1,x2,predict\", fmt='%.3f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Model Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import multiple_layer_perceptron as mlp\n",
    "from model import nnlayers\n",
    "import numpy as np\n",
    "\n",
    "net = mlp.get_model(INPUT_DIM, OUTPUT_DIM, HIDDEN_NUM, act_layer=nnlayers.Tanh()\n",
    "                    , output_layer=nnlayers.Sigmoid()\n",
    "                   )  # 3-layer forward neural network\n",
    "\n",
    "def squared_loss(y_hat, y):\n",
    "    \"\"\" MSE \"\"\"\n",
    "    return (y.reshape(y_hat.shape) - y_hat) ** 2 / 2, y.reshape(y_hat.shape) - y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data_util.DataLoader import DataSet, DataLoader\n",
    "from data_util.Animator import MyAnimator\n",
    "from train import train_per_epoch, eval_per_epoch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"start loading training data ...\")\n",
    "train_dataset = DataSet(DATA_DIR, split='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=3, shuffle=False)\n",
    "print(\"The number of training data is: %d.\" % len(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (1) Mini-Batch Backpropagation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "animator = MyAnimator(xlabel='epoch', xlim=[1, n_epochs],\n",
    "                        legend=['train loss', 'test loss'])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_metrics = train_per_epoch(net, train_dataloader, squared_loss, lr)\n",
    "    if epoch % 100 == 99:\n",
    "        animator.add(epoch + 1, train_metrics)\n",
    "\n",
    "print('Training mean loss: %f' % train_metrics)\n",
    "# animator.savefig('../fig/NN/training_loss_h=3_epoch=5000.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (2) Predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_10 = np.array([1873, 1478, 1900])\n",
    "predict_10 = net(input_10) * (maxValue - minValue) + minValue\n",
    "print(predict_10)\n",
    "\n",
    "# input_11 = np.array([1478, 1900, predict_10])\n",
    "# predict_11 = net(input_11)\n",
    "\n",
    "# input_12 = np.array([1900, predict_10, predict_11])\n",
    "# predict_12 = net(input_12)\n",
    "\n",
    "# print(\"Predict results: [10]: {}\\t[11]: {}\\t[12]: {}\".format(predict_10, predict_11, predict_12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538367d4-5908-40bd-aa2c-0f24a442d97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}